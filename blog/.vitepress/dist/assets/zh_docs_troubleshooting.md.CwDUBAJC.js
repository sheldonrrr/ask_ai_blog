import{_ as l,o as e,c as i,aj as o}from"./chunks/framework.C-Ix9pmH.js";const b=JSON.parse('{"title":"故障排除","description":"","frontmatter":{},"headers":[],"relativePath":"zh/docs/troubleshooting.md","filePath":"zh/docs/troubleshooting.md"}'),r={name:"zh/docs/troubleshooting.md"};function t(h,a,n,d,s,c){return e(),i("div",null,[...a[0]||(a[0]=[o('<h1 id="故障排除" tabindex="-1">故障排除 <a class="header-anchor" href="#故障排除" aria-label="Permalink to “故障排除”">​</a></h1><h2 id="请求失败" tabindex="-1">请求失败 <a class="header-anchor" href="#请求失败" aria-label="Permalink to “请求失败”">​</a></h2><ul><li>检查网络连接</li><li>验证 API 密钥是否正确</li><li>尝试其他 AI 提供商</li></ul><h2 id="api-密钥无效" tabindex="-1">API 密钥无效 <a class="header-anchor" href="#api-密钥无效" aria-label="Permalink to “API 密钥无效”">​</a></h2><ul><li>复制完整密钥，不要有空格</li><li>检查密钥是否过期</li><li>对于 Grok: 使用 console.x.ai 的密钥，不是 x.com</li></ul><h2 id="ollama-不工作" tabindex="-1">Ollama 不工作 <a class="header-anchor" href="#ollama-不工作" aria-label="Permalink to “Ollama 不工作”">​</a></h2><ol><li>确保 Ollama 已安装并运行</li><li>拉取模型: <code>ollama pull llama3.2</code></li><li>检查模型: <code>ollama list</code></li><li>确认服务运行: <code>ollama serve</code></li></ol><h2 id="常见问题" tabindex="-1">常见问题 <a class="header-anchor" href="#常见问题" aria-label="Permalink to “常见问题”">​</a></h2><h3 id="插件不显示在工具栏" tabindex="-1">插件不显示在工具栏 <a class="header-anchor" href="#插件不显示在工具栏" aria-label="Permalink to “插件不显示在工具栏”">​</a></h3><ol><li>安装后重启 calibre</li><li>检查 首选项 -&gt; 工具栏与菜单</li><li>确保插件已启用</li></ol><h3 id="响应很慢" tabindex="-1">响应很慢 <a class="header-anchor" href="#响应很慢" aria-label="Permalink to “响应很慢”">​</a></h3><ul><li>尝试其他 AI 提供商</li><li>检查你的网络连接</li><li>考虑使用更小/更快的模型</li></ul><h3 id="模型列表不加载" tabindex="-1">模型列表不加载 <a class="header-anchor" href="#模型列表不加载" aria-label="Permalink to “模型列表不加载”">​</a></h3><ul><li>验证你的 API 密钥是否正确</li><li>检查 Base URL 是否正确</li><li>尝试再次点击 &quot;加载模型列表&quot;</li></ul>',14)])])}const _=l(r,[["render",t]]);export{b as __pageData,_ as default};
